{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrations and Groups Calculator Notebook Demo\n",
    "This is a quick demo for the Integrations and Groups Calculator (`ExoCTK.integrations_groups`). This demo can run with a `Python3` install, an up-to-date `ExoCTK` install, and the data file for the Integrations and Groups calculator (more on this later.) \n",
    "\n",
    "The Integrations and Groups Calculator was written as an exoplanet focused alternative to the JWST ETC or `pandeia`. It's power comes from :\n",
    "1. Using pre-sampled data and interpolating for a speedy speedy speedy calculation. \n",
    "2. Having the power to provide you with the optimal configuration for your observation -- instead of just letting you guess and check configurations. \n",
    "\n",
    "This notebook has a few sections for clarity :\n",
    "* [Imports and Setup](#imports)\n",
    "* [Input Parameter Space](#input)\n",
    "* [Building an Input Dictionary](#dict)\n",
    "* [Running the Calculator](#calculate)\n",
    "* [Exploring the Outputs ](#outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "## Imports and Setup\n",
    "\n",
    "Other than `ExoCTK` -- you'll need the pre-sampled data the Integrations and Groups calculator runs on in a `JSON` format. The file is available from the Data tab or bottom right corner of the [ExoCTK Website](https://exoctk.stsci.edu/). \n",
    "\n",
    "If you followed the regular installation you should have this under the environment variable `INTEGRATIONS_DIR`, and we'll just take it from your `path` -- otherwise you'll need to specify the path in this cell. \n",
    "\n",
    "Also -- **DON'T WORRY** if you get a big scary warning about the `matplotlib` backend. We need that in there to run server side when we host the website -- but it won't affect any of this demo of your general `ExoCTK` usage. If it's truly too hideous run this cell twice and warning should vanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import os\n",
    "\n",
    "from exoctk.integrations_groups.integrations_groups import perform_calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if you have the environment variable\n",
    "INTEGRATIONS_DIR = os.environ.get('INTEGRATIONS_DIR')\n",
    "if INTEGRATIONS_DIR == '':\n",
    "    INTEGRATIONS_DIR = '/path/to/your/local/copy/integrations_groups_data.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='input'></a>\n",
    "## Input Parameter Space \n",
    "\n",
    "We are often adding functionality and modes to this -- so instead of providing a static list of what models, instrument modes, etc., are presently feasible, here's a little demo on how to walk through the data file yourself and see what parameters are possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Available modes for science :\n",
      "------------------------\n",
      "Instruments : ['niriss', 'nircam', 'nirspec', 'miri']\n",
      "Filters for niriss : ['soss']\n",
      "Subarrays for niriss : ['substrip96', 'substrip256']\n",
      "Filters for nircam : ['f444w', 'f277w', 'f322w2']\n",
      "Subarrays for nircam : ['subgrism128', 'full', 'subgrism256', 'subgrism64']\n",
      "Filters for nirspec : ['f070lp_g140h', 'f290lp_g395h', 'f170lp_g235m', 'f170lp_g235h', 'f070lp_g140m', 'f100lp_g140h', 'f100lp_g140m', 'f290lp_g395m']\n",
      "Subarrays for nirspec : ['sub1024a', 'sub1024b', 'sub2048', 'sub512']\n",
      "Filters for miri : ['lrs']\n",
      "Subarrays for miri : ['slitlessprism']\n",
      "\n",
      "\n",
      "Available modes for TA :\n",
      "------------------------\n",
      "Instruments : ['niriss', 'nircam', 'nirspec', 'miri']\n",
      "Filters for niriss : ['f480m']\n",
      "Subarrays for niriss : ['im', 'nrm']\n",
      "Filters for nircam : ['f335m']\n",
      "Subarrays for nircam : ['sub32tats']\n",
      "Filters for nirspec : ['f110w', 'f140x', 'clear']\n",
      "Subarrays for nirspec : ['sub2048', 'full', 'sub32']\n",
      "Filters for miri : ['f1500w', 'f100w', 'f560w']\n",
      "Subarrays for miri : ['slitlessprism']\n",
      "\n",
      "\n",
      "Phoenix model keys :\n",
      "---------------------\n",
      "['k0v', 'k5v', 'g5v', 'f5i', 'g0iii', 'f0i', 'k0iii', 'g2v', 'm0v', 'k5iii', 'm0i', 'g0v', 'g8v', 'f0v', 'g0i', 'm2i', 'a3v', 'f8v', 'k5i', 'a1v', 'f5v', 'a5v', 'a0i', 'f2v', 'm5v', 'm2v', 'a5i', 'a0v', 'k7v', 'k2v', 'k0i', 'g5iii', 'g5i', 'm0iii']\n",
      "\n",
      "\n",
      "Magnitude sampling :\n",
      "--------------------\n",
      "[4.5, 6.5, 8.5, 10.5, 12.5]\n"
     ]
    }
   ],
   "source": [
    "# Open the file\n",
    "with open(INTEGRATIONS_DIR) as f:\n",
    "    parameter_space = json.load(f)\n",
    "    \n",
    "# Print the TA and Science observation modes\n",
    "modes = [('science', 'sci_sat'), ('TA', 'ta_sat')]\n",
    "for mode in modes:\n",
    "    print('\\n')\n",
    "    print('Available modes for {} :'.format(mode[0]))\n",
    "    print('------------------------')\n",
    "    inss = list(parameter_space[mode[1]].keys())\n",
    "    print('Instruments : {}'.format(inss))\n",
    "    for ins in inss:\n",
    "        filts = list(parameter_space[mode[1]][ins].keys())\n",
    "        print('Filters for {} : {}'.format(ins, filts))\n",
    "        subs = list(parameter_space[mode[1]][ins][filts[0]].keys())\n",
    "        print('Subarrays for {} : {}'.format(ins, subs))\n",
    "\n",
    "# Print the available Phoenix models\n",
    "print('\\n')\n",
    "print('Phoenix model keys :')\n",
    "print('---------------------')\n",
    "print(list(parameter_space['ta_sat'][inss[-1]][filts[0]][subs[0]].keys()))\n",
    "\n",
    "print('\\n')\n",
    "print('Magnitude sampling :')\n",
    "print('--------------------')\n",
    "print(parameter_space['mags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dict'></a>\n",
    "## Building an Input Dictionary\n",
    "\n",
    "Running the Integrations and Groups Calculator requires a dictionary of inputs. This section will go through an example input dictionary and what the limits on the parameters are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the dictionary\n",
    "parameters = {}\n",
    "\n",
    "# Source parameters\n",
    "parameters['mag'] = 10 # 4.5 <= float <= 12.5\n",
    "parameters['band'] = 'k' # only K band vega mag for now\n",
    "parameters['mod'] = 'g2v' # Phoenix model per last section\n",
    "\n",
    "# Observation specifics \n",
    "parameters['obs_time'] = 5 # positive float, in hours\n",
    "parameters['n_group'] = 'optimize' # 'optimize', or positive integer\n",
    "\n",
    "# Detector setup -- within the modes of the last section\n",
    "parameters['ins'] = 'nircam'\n",
    "# For science observation\n",
    "parameters['filt'] = 'f444w'\n",
    "parameters['subarray'] = 'subgrism256'\n",
    "# And target acquisition\n",
    "parameters['filt_ta'] = 'f335m'\n",
    "parameters['subarray_ta'] = 'sub32tats'\n",
    "\n",
    "# Saturation level\n",
    "parameters['sat_mode'] = 'well' # 'well', for full well fraction, or 'counts' \n",
    "parameters['sat_max'] = .95 # < 1 for fullwell, and a positive integer always\n",
    "\n",
    "# And feed in the data file\n",
    "parameters['infile'] = INTEGRATIONS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='calculate'></a>\n",
    "## Running the Calculator \n",
    "\n",
    "Now, running the calculator is simple. We leaned on the `pandeia` function convention -- so feeding our inputs into `perform_calculation` returns a dictionary of input parameters (a stripped down `pandiea` scene) as well as the results of the calculation. (Note that `perform_calculation` updates the `parameters` dictionary -- so that object will be changed once you run the function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input of mag was 10.\n",
      "The input of band was k.\n",
      "The input of mod was g2v.\n",
      "The input of obs_time was 5.\n",
      "The input of n_group was 147.\n",
      "The input of ins was nircam.\n",
      "The input of filt was f444w.\n",
      "The input of subarray was subgrism256.\n",
      "The input of filt_ta was f335m.\n",
      "The input of subarray_ta was sub32tats.\n",
      "The input of sat_mode was well.\n",
      "The input of sat_max was 55195.0.\n",
      "The input of infile was REDACTED!\n",
      "The result of n_col was 256\n",
      "The result of n_row was 256\n",
      "The result of n_amp was 1\n",
      "The result of n_reset was 1\n",
      "The result of n_frame was 1\n",
      "The result of n_skip was 0\n",
      "The result of t_frame was 1.347\n",
      "The result of t_int was 197.963\n",
      "The result of t_ramp was 197.963\n",
      "The result of n_int was 91\n",
      "The result of t_exp was 5.004\n",
      "The result of t_duration was 5.038\n",
      "The result of obs_eff was 0.993\n",
      "The result of ta_t_frame was 0.01496\n",
      "The result of min_ta_groups was 33\n",
      "The result of max_ta_groups was 3\n",
      "The result of t_duration_ta_min was 0.50864\n",
      "The result of t_duration_ta_max was 0.05984\n",
      "The result of max_sat_prediction was 54944.595\n",
      "The result of max_sat_ta was 4620.26\n",
      "The result of min_sat_ta was 50822.861\n"
     ]
    }
   ],
   "source": [
    "# Bookeeping for new/old parameters\n",
    "inputs = list(parameters.keys())\n",
    "\n",
    "# Perform the calculation \n",
    "results = perform_calculation(parameters)\n",
    "for key in results:\n",
    "    if key in inputs:\n",
    "        if key == 'infile':\n",
    "            # hackers\n",
    "            print('The input of infile was REDACTED!')\n",
    "        else:\n",
    "            print('The input of {} was {}.'.format(key, results[key]))\n",
    "    else:\n",
    "        print('The result of {} was {}'.format(key, results[key]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='outputs'></a>\n",
    "## Exploring the Outputs\n",
    "\n",
    "If you aren't quite familiar with the intricacies of a JWST observation, we'll unpack these results briefly. \n",
    "\n",
    "Every JWST observation has a number of groups and integrations. Groups are how many frames you can pack into an integration, and generally this is goverened by how quickly your target will saturate on the detector. With every integration there is overhead time added into the observation, and less time observing your actual transit. So, once the calculator has figured out the maximum possible groups before the detector is saturated, it will return that number of groups, how many integrations of that pattern it takes to fill up your whole transit time, and some additional helpful parameters like what's the maximum saturation you might reach during this observation, how long the actual scheme will take (since there will be a slightly different rounding when everything is added up), how efficient your observation is, etc. \n",
    "\n",
    "For target acquisition, the efficiency is less in question that the ability of the detector to hit the minimum SNR required. This provides a reccomendation, so you know the minimum and maxmimum possible groups you can use, and can make an informed decision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total time for science + TA observation scheme is 5.097840000000001-5.54664 hours.\n",
      "You need 147 groups and 91 integrations for the science observation.\n",
      "You need between 3 and 33 groups for target acquisition.\n",
      "We estimate your science observation will reach at most 54944.595 counts -- how close were we to your cutoff of 55195.0?\n",
      "With this observation scheme 99.3% of the observation will be science data.\n"
     ]
    }
   ],
   "source": [
    "# So let's make a nice printed summary \n",
    "print('The total time for science + TA observation scheme is {}-{} hours.'.format(\n",
    "    results['t_duration']+results['t_duration_ta_max'], results['t_duration']+results['t_duration_ta_min']))\n",
    "print('You need {} groups and {} integrations for the science observation.'.format(\n",
    "    results['n_group'], results['n_int']))\n",
    "print('You need between {} and {} groups for target acquisition.'.format(\n",
    "    results['max_ta_groups'], results['min_ta_groups']))\n",
    "print('We estimate your science observation will reach at most {} counts -- how close were we to your cutoff of {}?'.format(\n",
    "    results['max_sat_prediction'], results['sat_max']))\n",
    "print('With this observation scheme {}% of the observation will be science data.'.format(results['obs_eff']*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
