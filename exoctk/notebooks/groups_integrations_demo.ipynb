{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groups and Integrations Calculator Notebook Demo\n",
    "This is a quick demo for the Groups and Integrations Calculator (`exoCTK.groups_integrations`). This demo can run with a `Python3` install, an up-to-date `exoctk` install, and the data file for the Groups and Integrations calculator (more on this later.) \n",
    "\n",
    "The Groups and Integrations Calculator was written as an exoplanet focused alternative to the JWST ETC or `pandeia`. It's power comes from :\n",
    "1. Using pre-sampled data and interpolating for a speedy speedy speedy calculation. \n",
    "2. Having the power to provide you with the optimal configuration for your observation -- instead of just letting you guess and check configurations. \n",
    "\n",
    "This notebook has a few sections for clarity :\n",
    "* [Imports and Setup](#imports)\n",
    "* [Input Parameter Space](#input)\n",
    "* [Building an Input Dictionary](#dict)\n",
    "* [Running the Calculator](#calculate)\n",
    "* [Exploring the Outputs ](#outputs)\n",
    "* [Two Examples for Batch Runs](#batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "## Imports and Setup\n",
    "\n",
    "Other than `ExoCTK` -- you'll need the pre-sampled data the Integrations and Groups calculator runs on in a `JSON` format. The file is available from the Data tab or bottom right corner of the [ExoCTK Website](https://exoctk.stsci.edu/). \n",
    "\n",
    "If you followed the regular installation you should have this under the environment variable `EXOCTK_DATA`, and we'll just take it from your `path` -- otherwise you'll need to specify the path in this cell. \n",
    "\n",
    "Also -- **DON'T WORRY** if you get a big scary warning about the `matplotlib` backend. We need that in there to run server side when we host the website -- but it won't affect any of this demo of your general `exoctk` usage. If it's truly too hideous run this cell twice and warning should vanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import os\n",
    "\n",
    "from exoctk.groups_integrations.groups_integrations import perform_calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if you have the environment variable\n",
    "\n",
    "EXOCTK_DATA = os.environ.get('EXOCTK_DATA')\n",
    "if EXOCTK_DATA == '':\n",
    "    GROUPS_INTEGRATIONS_DIR = '/path/to/your/local/copy/integrations_groups_data.json'\n",
    "else:\n",
    "    GROUPS_INTEGRATIONS_DIR = GROUPS_INTEGRATIONS_DIR = os.path.join(EXOCTK_DATA, 'groups_integrations/groups_integrations.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='input'></a>\n",
    "## Input Parameter Space \n",
    "\n",
    "We are often adding functionality and modes to this -- so instead of providing a static list of what models, instrument modes, etc., are presently feasible, here's a little demo on how to walk through the data file yourself and see what parameters are possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Available modes for science :\n",
      "------------------------\n",
      "Instruments : ['niriss', 'nircam', 'nirspec', 'miri']\n",
      "Filters for niriss : ['soss']\n",
      "Subarrays for niriss : ['substrip96', 'substrip256']\n",
      "Filters for nircam : ['f444w', 'f277w', 'f322w2']\n",
      "Subarrays for nircam : ['subgrism128', 'full', 'subgrism256', 'subgrism64']\n",
      "Filters for nirspec : ['f070lp_g140h', 'f290lp_g395h', 'f170lp_g235m', 'f170lp_g235h', 'f070lp_g140m', 'f100lp_g140h', 'f100lp_g140m', 'f290lp_g395m']\n",
      "Subarrays for nirspec : ['sub1024a', 'sub1024b', 'sub2048', 'sub512']\n",
      "Filters for miri : ['lrs']\n",
      "Subarrays for miri : ['slitlessprism']\n",
      "\n",
      "\n",
      "Available modes for TA :\n",
      "------------------------\n",
      "Instruments : ['niriss', 'nircam', 'nirspec', 'miri']\n",
      "Filters for niriss : ['f480m']\n",
      "Subarrays for niriss : ['im', 'nrm']\n",
      "Filters for nircam : ['f335m']\n",
      "Subarrays for nircam : ['sub32tats']\n",
      "Filters for nirspec : ['f110w', 'f140x', 'clear']\n",
      "Subarrays for nirspec : ['sub2048', 'full', 'sub32']\n",
      "Filters for miri : ['f1500w', 'f100w', 'f560w']\n",
      "Subarrays for miri : ['slitlessprism']\n",
      "\n",
      "\n",
      "Phoenix model keys :\n",
      "---------------------\n",
      "['k0v', 'k5v', 'g5v', 'f5i', 'g0iii', 'f0i', 'k0iii', 'g2v', 'm0v', 'k5iii', 'm0i', 'g0v', 'g8v', 'f0v', 'g0i', 'm2i', 'a3v', 'f8v', 'k5i', 'a1v', 'f5v', 'a5v', 'a0i', 'f2v', 'm5v', 'm2v', 'a5i', 'a0v', 'k7v', 'k2v', 'k0i', 'g5iii', 'g5i', 'm0iii']\n",
      "\n",
      "\n",
      "Magnitude sampling :\n",
      "--------------------\n",
      "[4.5, 6.5, 8.5, 10.5, 12.5]\n"
     ]
    }
   ],
   "source": [
    "# Open the file\n",
    "with open(GROUPS_INTEGRATIONS_DIR) as f:\n",
    "    parameter_space = json.load(f)\n",
    "    \n",
    "# Print the TA and Science observation modes\n",
    "modes = [('science', 'sci_sat'), ('TA', 'ta_sat')]\n",
    "for mode in modes:\n",
    "    print('\\n')\n",
    "    print('Available modes for {} :'.format(mode[0]))\n",
    "    print('------------------------')\n",
    "    inss = list(parameter_space[mode[1]].keys())\n",
    "    print('Instruments : {}'.format(inss))\n",
    "    for ins in inss:\n",
    "        filts = list(parameter_space[mode[1]][ins].keys())\n",
    "        print('Filters for {} : {}'.format(ins, filts))\n",
    "        subs = list(parameter_space[mode[1]][ins][filts[0]].keys())\n",
    "        print('Subarrays for {} : {}'.format(ins, subs))\n",
    "\n",
    "# Print the available Phoenix models\n",
    "print('\\n')\n",
    "print('Phoenix model keys :')\n",
    "print('---------------------')\n",
    "print(list(parameter_space['ta_sat'][inss[-1]][filts[0]][subs[0]].keys()))\n",
    "\n",
    "print('\\n')\n",
    "print('Magnitude sampling :')\n",
    "print('--------------------')\n",
    "print(parameter_space['mags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dict'></a>\n",
    "## Building an Input Dictionary\n",
    "\n",
    "Running the Groups and Integrations Calculator requires a dictionary of inputs. This section will go through an example input dictionary and what the limits on the parameters are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the dictionary\n",
    "parameters = {}\n",
    "\n",
    "# Source parameters\n",
    "parameters['mag'] = 10 # 4.5 <= float <= 12.5\n",
    "parameters['band'] = 'k' # only K band vega mag for now\n",
    "parameters['mod'] = 'g2v' # Phoenix model per last section\n",
    "\n",
    "# Observation specifics \n",
    "parameters['obs_time'] = 5 # positive float, in hours\n",
    "parameters['n_group'] = 'optimize' # 'optimize', or positive integer\n",
    "\n",
    "# Detector setup -- within the modes of the last section\n",
    "parameters['ins'] = 'nircam'\n",
    "# For science observation\n",
    "parameters['filt'] = 'f444w'\n",
    "parameters['subarray'] = 'subgrism256'\n",
    "# And target acquisition\n",
    "parameters['filt_ta'] = 'f335m'\n",
    "parameters['subarray_ta'] = 'sub32tats'\n",
    "\n",
    "# Saturation level\n",
    "parameters['sat_mode'] = 'well' # 'well', for full well fraction, or 'counts' \n",
    "parameters['sat_max'] = .95 # < 1 for fullwell, and a positive integer always\n",
    "\n",
    "# And feed in the data file\n",
    "parameters['infile'] = GROUPS_INTEGRATIONS_DIR\n",
    "input_dict = parameters.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='calculate'></a>\n",
    "## Running the Calculator \n",
    "\n",
    "Now, running the calculator is simple. We leaned on the `pandeia` function convention -- so feeding our inputs into `perform_calculation` returns a dictionary of input parameters (a stripped down `pandiea` scene) as well as the results of the calculation. (Note that `perform_calculation` updates the `parameters` dictionary -- so that object will be changed once you run the function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input of mag was 10.\n",
      "The input of band was k.\n",
      "The input of mod was g2v.\n",
      "The input of obs_time was 5.\n",
      "The input of n_group was 147.\n",
      "The input of ins was nircam.\n",
      "The input of filt was f444w.\n",
      "The input of subarray was subgrism256.\n",
      "The input of filt_ta was f335m.\n",
      "The input of subarray_ta was sub32tats.\n",
      "The input of sat_mode was well.\n",
      "The input of sat_max was 55195.0.\n",
      "The input of infile was REDACTED!\n",
      "The result of n_col was 256\n",
      "The result of n_row was 256\n",
      "The result of n_amp was 1\n",
      "The result of n_reset was 1\n",
      "The result of n_frame was 1\n",
      "The result of n_skip was 0\n",
      "The result of t_frame was 1.347\n",
      "The result of t_int was 197.963\n",
      "The result of t_ramp was 197.963\n",
      "The result of n_int was 91\n",
      "The result of t_exp was 5.004\n",
      "The result of t_duration was 5.038\n",
      "The result of obs_eff was 0.993\n",
      "The result of ta_t_frame was 0.01496\n",
      "The result of min_ta_groups was 33\n",
      "The result of max_ta_groups was 3\n",
      "The result of t_duration_ta_min was 0.50864\n",
      "The result of t_duration_ta_max was 0.05984\n",
      "The result of max_sat_prediction was 54944.595\n",
      "The result of max_sat_ta was 4620.26\n",
      "The result of min_sat_ta was 50822.861\n"
     ]
    }
   ],
   "source": [
    "# Bookeeping for new/old parameters\n",
    "inputs = list(parameters.keys())\n",
    "\n",
    "# Perform the calculation \n",
    "results = perform_calculation(parameters)\n",
    "for key in results:\n",
    "    if key in inputs:\n",
    "        if key == 'infile':\n",
    "            # hackers\n",
    "            print('The input of infile was REDACTED!')\n",
    "        else:\n",
    "            print('The input of {} was {}.'.format(key, results[key]))\n",
    "    else:\n",
    "        print('The result of {} was {}'.format(key, results[key]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='outputs'></a>\n",
    "## Exploring the Outputs\n",
    "\n",
    "If you aren't quite familiar with the intricacies of a JWST observation, we'll unpack these results briefly. \n",
    "\n",
    "Every JWST observation has a number of groups and integrations. Groups are how many frames you can pack into an integration, and generally this is goverened by how quickly your target will saturate on the detector. With every integration there is overhead time added into the observation, and less time observing your actual transit. So, once the calculator has figured out the maximum possible groups before the detector is saturated, it will return that number of groups, how many integrations of that pattern it takes to fill up your whole transit time, and some additional helpful parameters like what's the maximum saturation you might reach during this observation, how long the actual scheme will take (since there will be a slightly different rounding when everything is added up), how efficient your observation is, etc. \n",
    "\n",
    "For target acquisition, the efficiency is less in question that the ability of the detector to hit the minimum SNR required. This provides a reccomendation, so you know the minimum and maxmimum possible groups you can use, and can make an informed decision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total time for science + TA observation scheme is 5.097840000000001-5.54664 hours.\n",
      "You need 147 groups and 91 integrations for the science observation.\n",
      "You need between 3 and 33 groups for target acquisition.\n",
      "We estimate your science observation will reach at most 54944.595 counts -- how close were we to your cutoff of 55195.0?\n",
      "With this observation scheme 99.3% of the observation will be science data.\n"
     ]
    }
   ],
   "source": [
    "# So let's make a nice printed summary \n",
    "print('The total time for science + TA observation scheme is {}-{} hours.'.format(\n",
    "    results['t_duration']+results['t_duration_ta_max'], results['t_duration']+results['t_duration_ta_min']))\n",
    "print('You need {} groups and {} integrations for the science observation.'.format(\n",
    "    results['n_group'], results['n_int']))\n",
    "print('You need between {} and {} groups for target acquisition.'.format(\n",
    "    results['max_ta_groups'], results['min_ta_groups']))\n",
    "print('We estimate your science observation will reach at most {} counts -- how close were we to your cutoff of {}?'.format(\n",
    "    results['max_sat_prediction'], results['sat_max']))\n",
    "print('With this observation scheme {}% of the observation will be science data.'.format(results['obs_eff']*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='batch'></a>\n",
    "## Two Examples for Batch Runs\n",
    "\n",
    "So far we've shown you how to run this one off -- just like you would the website. But perhaps that doesn't excite you like it does us? Here are two examples for running many calculations. Because the calculator is so light and only has a single parameter, it won't be particularly computationally expensive or logistically difficult to parallelize. The bulk of the code below is to neatly set up several examples.\n",
    "\n",
    "So -- here are two examples : \n",
    "* [Checking many potential observations in *one* instrument/mode/filter.](#source)\n",
    "* [Checking one transit in *many* instruments/modes/filters.](#mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some imports/set up for ease of this part of the demo\n",
    "from multiprocessing import Pool\n",
    "p = Pool(4) # Feel free to set it higher but this will place nice with most laptops.\n",
    "\n",
    "from astropy.io import ascii\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='source'></a>\n",
    "First we run over a few objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Say you have a table of sources you want to read in. \n",
    "# sources = ascii.read('path/to/source_table.csv')\n",
    "# Since we don't we'll just make one up with reasonable transit objects\n",
    "sources = {'mod': ['k0v', 'k5v', 'g5v', 'f5i', 'g0iii', 'f0i', 'k0iii', 'g2v', 'm0v', 'k5iii', 'm0i', 'g0v', 'g8v', 'f0v', 'g0i'],\n",
    "           'obs_time': [3 + n*.15 for n in range(15)], \n",
    "           'mag': [9 + n*.15 for n in range(15)]}\n",
    "\n",
    "# Now use this to create input dictionaries\n",
    "input_sources = []\n",
    "for index, elem in enumerate(sources['mod']):\n",
    "    input_source = input_dict.copy()\n",
    "    input_source['mod'] = elem\n",
    "    input_source['obs_time'] = sources['obs_time'][index]\n",
    "    input_source['mag'] = sources['mag'][index]\n",
    "    input_sources.append(input_source)\n",
    "\n",
    "\n",
    "# And run it in parallel\n",
    "single_mode_results = p.map(perform_calculation, input_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the best sources is g8v, 4.8, 10.8 at 0.997 efficiency.\n",
      "(This means 302 groups and 43 integrations.)\n",
      "One of the best sources is f0v, 4.95, 10.95 at 0.997 efficiency.\n",
      "(This means 336 groups and 40 integrations.)\n",
      "One of the best sources is g0i, 5.1, 11.1 at 0.997 efficiency.\n",
      "(This means 379 groups and 36 integrations.)\n"
     ]
    }
   ],
   "source": [
    "# And explore the output\n",
    "obs_eff = [result['obs_eff'] for result in single_mode_results]\n",
    "indeces = np.where(obs_eff == np.max(obs_eff))[0]\n",
    "bests = [single_mode_results[index] for index in indeces]\n",
    "for best in bests:\n",
    "    print('One of the best sources is {}, {}, {} at {} efficiency.'.format(best['mod'], best['obs_time'], best['mag'], best['obs_eff']))\n",
    "    print('(This means {} groups and {} integrations.)'.format(best['n_group'], best['n_int']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mode'></a>\n",
    "Now a few different instrument setups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're starting at a baseline of 0.984 efficiency.\n",
      "Source : k0v, 9.0, 3.0 mode.\n",
      "Mode : nircam, f444w, subgrism256\n"
     ]
    }
   ],
   "source": [
    "# Let's take the LEAST efficient observation from the last example\n",
    "# We'll see if it plays more nicely with another instrument, filter, or subarray. \n",
    "worst = single_mode_results[np.where(obs_eff == np.min(obs_eff))[0][0]]\n",
    "print(\"We're starting at a baseline of {} efficiency.\".format(worst['obs_eff']))\n",
    "print('Source : {}, {}, {} mode.'.format(worst['mod'], worst['mag'], worst['obs_time']))\n",
    "print('Mode : {}, {}, {}'.format(worst['ins'], worst['filt'], worst['subarray']))\n",
    "for key in ['mod', 'mag', 'obs_time']:\n",
    "    input_dict[key] = worst[key]\n",
    "\n",
    "# We'll call back to the parameter_space dictionary we walked through to look at available modes\n",
    "modes = []\n",
    "for ins in parameter_space['sci_sat'].keys():\n",
    "    for filt in parameter_space['sci_sat'][ins].keys():\n",
    "        for sub in parameter_space['sci_sat'][ins][filt].keys():\n",
    "            input_mode = input_dict.copy()\n",
    "            \n",
    "            # Alter the science setup\n",
    "            input_mode['ins'] = ins\n",
    "            input_mode['filt'] = filt\n",
    "            input_mode['subarray'] = sub\n",
    "            \n",
    "            # And we care less about TA so pick the default for each instrument\n",
    "            input_mode['filt_ta'] = list(parameter_space['ta_sat'][ins].keys())[0]\n",
    "            input_mode['subarray_ta'] = list(parameter_space['ta_sat'][ins][input_mode['filt_ta']].keys())[0]\n",
    "            modes.append(input_mode)\n",
    "\n",
    "# And run it in parallel\n",
    "single_source_results = p.map(perform_calculation, modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best mode is nircam, f444w, subgrism64 at 0.996 efficiency.\n",
      "(This means 230 groups and 138 integrations.)\n"
     ]
    }
   ],
   "source": [
    "# And, again explore the output\n",
    "obs_eff = [result['obs_eff'] for result in single_source_results]\n",
    "indeces = np.where(obs_eff == np.max(obs_eff))[0]\n",
    "bests = [single_source_results[index] for index in indeces]\n",
    "for best in bests:\n",
    "    print('The best mode is {}, {}, {} at {} efficiency.'.format(best['ins'], best['filt'], best['subarray'], best['obs_eff']))\n",
    "    print('(This means {} groups and {} integrations.)'.format(best['n_group'], best['n_int']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
